---
class: middle, center

# 架构

.center[.width-110[![](./figures/archi2.png)]]

---
# 相关技术

- 数据采集
  - 物联网、传感器网络、视频采集技术和传输技术
- 存储领域
  - 存储、分片、通信、容错
- 处理领域
  - 云计算、网格计算

---
# 计算模式

- 两种数据和两种计算
  - 离线数据（持久存储）：离线计算
  - 实时数据（消息队列）：流式计算

.center[.width-110[![](./figures/ali.png)]]

---
# 框架

- 按处理的数据形式和得到结果的时效性，分两类
- 批处理框架：离线计算
  - 对已经存在的一个大规模数据集进行处理
  - Apache Hadoop
- 流处理框架：流式计算
  - 数据从外部系统连续不断流入，系统逐项或微批处理
  - Apache Storm
- 混合框架
  - 同时支持批处理和流处理
  - Apache Spark

???

离线计算：即批处理，建议大家去学习开源的MapReduce和Spark；
在线计算：也称为即席查询，建议大家去学习Presto、Impala和Drill；

阿里云的在线计算
分析型数据库MySQL版：是阿里巴巴自主研发的海量数据实时高并发在线分析（Realtime OLAP），完全兼容MySQL；帮助文档
分析型数据库PostgreSQL版：通过分析型数据库PostgreSQL版可以实现对海量数据的即席查询分析、ETL 处理及可视化探索，是各行业有竞争力的云上数据仓库解决方案；帮助文档

流式计算：目前业界关注最多的场景，建议大家重点去学习Flink，阿里云的实时计算服务也是基于Flink之上提供服务的

.center[.width-100[![](./figures/scene.png)]]

---
# 批处理框架

- 在大数据世界中有着悠久的历史
- 对已经存在的一个大规模数据集进行处理
- 处理非常巨大的数据集时，批处理系统最有效
  - 适合操作海量静态数据
- 常用于处理历史记录信息
  - 等到这一批量处理完成后，得到处理结果
- 处理海量数据通常需要耗费很多时间，所以不适合实时性要求较高的场景

???
- 有限性
  - 数据的有限集合 (连续不断的数据一般会使用流处理系统来进行处理)
- 持久性
  - 系统处理的数据一般存储在持久存储系统(硬盘、数据库)
- 海量性
  - 为处理海量数据而生
  - 极海量的数据通常只能使用批处理系统来进行集中处理
  - 在设计之初就充分考虑了数据量巨大的问题

---
class: middle, center

# 流处理框架

.center[.width-60[![](./figures/stream.jpg)]]

数据就像水流一样永不停止

对外部系统源源不断接入的数据进行实时处理

???

小学的时候可能我们经常会遇到这样的数学题类型：

一个水池有一个进水管和一个出水管，只打开进水管8个小时充满水，只打开出水管6个小时流光水，那么同时打开进水管和出水管，水池多长时间充满水?

看到这里，大家是不是在各种列方程式来解答这道题呢？大家的答案不知道是否和我的一样，这个水池永远也充不满！因为出水管出水比较快。

「流处理系统」就相当于这个「水池」，把流进来的「水」就相当于「数据」，比如我们加「盐」让他变成「盐水」，然后再把加工过「盐水」，即「处理过的数据」，从出水管放出去。这样，

---
# 两种处理方式

- 逐项处理
  - 每次处理一条数据
  - 真正意义上的流处理
- 微批处理
  - 把一小段时间内的数据当作一个微批次
  - 对这个微批次内的数据进行处理

---
# 特点

- 基于事件
  - 最新的数据也许更重要
- 处理结果立刻可用，并会随着新数据抵达持续更新
- 除非明确停止，否则没有「尽头」
- 应用
  - 分析错误日志
  - 评估基于时间的各种指标，比如变动或峰值，以尽快做出响应
  - 关注一段时间内的变化趋势

???
- 相关，在特定时间只能代表某个单一数据项。

流处理中的数据集是「无边界」的，这就产生了几个重要的影响：

①、完整数据集只能代表截至目前已经进入到系统中的数据总量。

（4）、流处理适应对象：（几乎）无限量的且需要响应的数据

流处理系统可以处理几乎无限量的数据，但同一时间只能处理一条(真正的流处理)或很少量(微批处理，Micro-batch Processing)数据，不同记录间只维持最少量的状态。虽然大部分系统提供了用于维持某些状态的方法，但流处理主要针对副作用更少，更加功能性的处理(Functional processing)进行优化。

功能性操作主要侧重于状态或副作用有限的离散步骤。针对同一个数据执行同一个操作会或略其他因素产生相同的结果，此类处理非常适合流处理，因为不同项的状态通常是某些困难、限制，以及某些情况下不需要的结果的结合体。因此虽然某些类型的状态管理通常是可行的，但这些框架通常在不具备状态管理机制时更简单也更高效。

此类处理非常适合某些类型的工作负载。有近实时处理需求的任务很适合使用流处理模式。

---
# 流处理系统的优势和现状

- 实时性远好于批处理系统
  - 能够尽快看到计算结果
- 适合实时性要求较高的场景
  - 日志分析
  - 设备监控
  - 实时流量变化
- 应用越来越广泛

---
# 混合处理系统

- 既可以批处理，也可以流处理
- 使用相同或相关的API处理历史和实时数据
- Spark
  - 如果说大数据处理框架群星闪耀，那Spark就是所有星星中最闪亮的那一颗

???
虽然专注于一种处理方式可能非常适合特定场景，但是混合框架为数据处理提供了通用的解决方案。

---
# 小结

- Apache Hadoop
  - 如果企业中只需要批处理工作，并且对时间并不敏感，那么可以使用成本较其他解决方案更低的Hadoop集群
- Storm
  - 如果企业仅进行流处理，并且对低延迟有着较高要求，Storm更加适合
  - 如果对延迟不非常敏感，可以使用Spark Streaming
- Apache Spark
  - 如果需要同时兼顾批处理与流处理任务，那么Spark是一个很好的选择。混合处理框架的另一个好处是，降低了开发人员的学习成本，从而为企业节约人力成本

???

- Flink提供了真正的流处理能力并且同样具备批处理能力，但商用案例较少，对于初次尝试数据处理的企业来说，大规模使用Flink存在一定风险。

---
# Apache Hadoop 框架

.center[.width-100[![](./figures/hadoop.jpg)]]

- MapReduce计算模型
- 分布式计算
- 各种工具


???
说起大数据处理框架，永远也绕不开Hadoop。Hadoop的处理功能来自MapReduce引擎。MapReduce的处理技术符合使用键值对的map、shuffle、reduce算法要求。

①、 从HDFS文件系统读取数据集

②、将数据集拆分成小块并分配给所有可用节点

③、 针对每个节点上的数据子集进行计算(计算的中间态结果会重新写入HDFS)

④、重新分配中间态结果并按照键进行分组

⑤、通过对每个节点计算的结果进行汇总和组合对每个键的值进行「Reducing」

⑥、将计算而来的最终结果重新写入HDFS

---
# Hadoop分布式文件系统

- 简称HDFS
- 很高容错性
- 部署在廉价机器集群上
- 能提供高吞吐量数据访问
- 非常适合大数据
- 可存储数据源、计算结果


---
# 资源管理器YARN

- 为上层应用提供统一的资源管理和调度
  - 管理服务器的资源(主要是CPU和内存)
  - 调度作业的运行
- 应用
  - Hadoop，Spark

???

在Hadoop中，它被设计用来管理MapReduce的计算服务。但现在很多其他的大数据处理框架也可以将YARN作为资源管理器，比如Spark。

MapReduce

为Hadoop中默认的数据处理引擎，也是Google的MapReduce论文思想的开源实现。使用HDFS作为数据源，使用YARN进行资源管理。

---
# Hadoop优势

- 基于持久存储（硬盘）
- 可以在廉价硬件上运行
- 能够存储和处理海量数据

???

- 但另一方面由于磁盘空间通常是服务器上最丰富的资源，这意味着MapReduce可以处理非常海量的数据集。同时也意味着相比其他类似技术，Hadoop的MapReduce通常可以在廉价硬件上运行，因为该技术并不需要将一切都存储在内存中。MapReduce具备极高的缩放潜力，生产环境中曾经出现过包含数万个节点的应用。

MapReduce的学习曲线较为陡峭，虽然Hadoop生态系统的其他周边技术可以大幅降低这一问题的影响，但通过Hadoop集群快速实现某些应用时依然需要注意这个问题。

围绕Hadoop已经形成了辽阔的生态系统，Hadoop集群本身也经常被用作其他软件的组成部件。很多其他处理框架和引擎通过与Hadoop集成也可以使用HDFS和YARN资源管理器。

---
# Hadoop局限

- 性能
  - 因为硬盘的读取和写入速度限制，速度较慢，不适合叠代计算(机器学习、图计算)
  - 任务的启动和调度开销较大
- 编程
  - 编程模型抽象程度低，仅支持Map和Reduce两种操作
  - 需手工编写大量代码
- 现状
  - 企业中应用已呈下降趋势
  - 最早的大数据处理引擎，仍然值得理解
  - HDFS及YARN仍然被广泛使用

???

从今天的眼光来看，MapReduce作为Hadoop默认的数据处理引擎，存在着很多的不足。比如：
随着更多高性能处理引擎的发展，

---
# Apache Storm

.center[.width-100[![](./figures/storm.jpg)]]

低延迟流处理框架，可处理海量接入数据，近实时方式处理数据，延时可达到亚秒级

---
# Storm关键概念：拓扑

- 实时计算的图状结构
  - 描述了数据片段进入系统后，对每个片段执行的不同转换或步骤
- 拓扑执行
  - 拓扑被提交给集群
  - 集群中的主控节点（master node）将任务分配给工作节点（worker node）执行
  - Storm可对拓扑的DAG(Directed Acyclic Graph，有向无环图)进行编排

---
# Storm关键概念：角色

- Spout
  - 位于拓扑边缘的数据流来源
  - 将数据流以tuple元组的形式发送出去
  - 可以是API或查询等，从这里可以产生待处理的数据
  - 发射出的tuple是不可变数组，对应着固定的键值对
- Bolt
  - 转换数据流，完成计算、过滤等操作
  - bolt可随机将数据发送给其他bolt
  - 在拓扑的尾部，使用最终的Bolt输出作为相互连接的其他系统的输入

???

拓扑包含：

①、Stream：普通的数据流，这是一种会持续抵达系统的无边界数据。

---
# Storm优势和局限

- 可能是近实时处理领域的最佳解决方案
  - 极低延迟
- 互操作性
  - 可与Hadoop的YARN资源管理器集成，很方便地融入现有Hadoop部署
  - 支持多种语言，为用户的拓扑定义提供了更多选择

???

Storm与Trident配合使得用户可以用微批代替纯粹的流处理。虽然借此用户可以获得更大灵活性打造更符合要求的工具，但同时这种做法会削弱该技术相比其他解决方案最大的优势。话虽如此，但多一种流处理方式总是好的。

Core Storm无法保证消息的处理顺序。Core Storm为消息提供了「至少一次」的处理保证，这意味着可以保证每条消息都能被处理，但也可能发生重复。Trident提供了严格的一次处理保证，可以在不同批之间提供顺序处理，但无法在一个批内部实现顺序处理。

Trident拓扑包含：

①、流批(Stream batch)：这是指流数据的微批，可通过分块提供批处理语义。

②、操作(Operation)：是指可以对数据执行的批处理过程。

对于延迟需求很高的纯粹的流处理工作负载，Storm可能是最适合的技术。该技术可以保证每条消息都被处理，可配合多种编程语言使用。由于Storm无法进行批处理，如果需要这些能力可能还需要使用其他软件。如果对严格的一次处理保证有比较高的要求，此时可考虑使用Trident。不过这种情况下其他流处理框架也许更适合。

Samza

3、Apache Samza

（1 ）Apache Samza概念

Samza处理数据流时，会分别按次处理每条收到的消息。Samza的流单位既不是元组，也不是Dstream，而是一条条消息。在Samza中，数据流被切分开来，每个部分都由一组只读消息的有序数列构成，而这些消息每条都有一个特定的ID（offset）。该系统还支持批处理，即逐次处理同一个数据流分区的多条消息。Samza的执行与数据流模块都是可插拔式的，尽管Samza的特色是依赖Hadoop的Yarn（另一种资源调度器）和Apache Kafka。所以提到Apache Samza，就不得不提到当前最流行的大数据消息中间件：Apache Kafka。Apache Kafka是一个分布式的消息中间件系统，具有高吞吐、低延时等特点，并且自带了容错机制。

---
# Kafka

.center[.width-100[![](./figures/kafka.jpg)]]

.center[分布式消息中间件]

---
# Kafka关键概念

- Broker
 - 分布式消息中间件，用多个节点来存储数据
 - Kafka集群中的单个节点
- Topic
  - 存储写入Kafka的数据流
  - 不同主题的数据流最好写入不同Topic，方便后续处理

---
# Kafka关键概念

- Partition
  - 每个Topic都有1到多个Partition，分散到不同的broker中
  - 多个partition组成一个Topic
- Producer
  - 消息生产者，将消息写入Kafka集群
- Consumer
  - 消息消费者，读取Kafka中的消息并进行处理

---
# Apache Spark

.center[.width-90[![](./figures/spark.jpg)]]

- Spark Core 批处理，Spark Streaming流处理
- 图计算(GraphX)、交互式查询(Spark SQL)、机器学习(MLlib)

---
# Spark

- 加州大学伯克利分校AMP实验室开发
- 受到了Hadoop的启发
- 优势
  - 通过内存计算模型和执行优化大幅提高了数据处理能力
  - 速度可以达到Hadoop的10-100倍，甚至更高

---
# 设计特点

- 内存计算模型 RDD
  - Resilient Distributed Dataset，弹性分布式数据集
  - 将数据读入内存中生成一个RDD，再对RDD进行计算
  - 每次计算结果可以缓存在内存中，减少了磁盘IO
  - 因此很适用于机器学习叠代计算

- DAG编程模型
  - 不同于Hadoop的简单MR模型
  - 将不同步骤操作串联成一个有向无环图，有效减少任务间数据传递，提高了性能

---
# 优势

- 编程模型
  - 提供了丰富的编程模型
  - 可以轻松实现过滤、连接、聚合等操作
  - 代码量相比MapReduce极大减少
  - 极大提高开发人员的生产力
- 编程语言
  - 支持Java、Scala、Python和R四种编程语言
  - 为不同语言的使用者降低了学习成本

---
# Spark Streaming

- 核心Spark API的一个扩展
- DStream（Discretized Stream）微批处理
  - 不像Storm逐个处理数据流，而是在处理前按时间间隔预先将其切分为一段一段的批处理作业
  - 一个DStream是一个微批处理（micro-batching）的RDD（弹性分布式数据集）

---
# Spark Streaming 特点

- 优点
  - 通过 RDD 实现了批处理和流处理的统一编程
  - 可重用批处理模块代码，开发人员不必学习两套编程模型
- 缺点
  - 由于内存是比硬盘更昂贵的资源，所以Spark集群成本比Hadoop集群高
  - 与Storm等原生的流处理系统相比，Spark Streaming的延时会相对高一些

???
而Spark的流处理能力，则是由Spark Streaming模块提供的。Spark在设计之初与MapReduce一样是用于批处理系统，为了适应于流处理模式，Spark提出了微批次(Micro-Batch)的概念，即把一小段时间内的接入数据作为一个微批次来处理。这样做的优点是在设计Spark Streaming时可以很大程度上


（3）Spark的局限性

但Spark也不是没有缺点。在批处理领域，由于内存是比硬盘更昂贵的资源，所以Spark集群的成本比MapReduce集群更高。而在流处理领域，微批次的架构使得它的延时要比Storm等流处理系统略高。不过瑕不掩瑜，Spark依然是如今最炙手可热的数据处理框架。

???

Apache Flink

2、Apache Flink

有趣的是，同样作为混合处理框架，Flink的思想与Spark是完全相反的：Spark把流拆分成若干个小批次来处理，而Flink把批处理任务当作有界的流来处理。其本质原因是，Spark最初是被设计用来进行批处理的，而Flink最初是被设计用来进行流处理的。这种流处理优先的方式叫做Kappa架构，与之相对的使用批处理优先的架构叫做Lambda架构。Kappa架构会使用处理流的方式处理一切，以此来简化编程模型。这一切是在最近流处理引擎逐渐成熟起来才有可能实现的。

（1 ）Flink流处理模型

Flink的流处理模型将逐项输入的数据作为真实的流处理。Flink提供了DataStream API用于处理无尽的数据流。

Flink的基本组件包括：

①、Stream(流)是指在系统中流转的，永恒不变的无边界数据集

②、Operator：Operator(操作方)是指针对数据流执行操作以产生其他数据流的功能

③、Source：Source(源)是指数据流进入系统的入口点④、Sink：Sink是数据流(stream)流出Flink系统后的位置。

④、Sink(槽)是指数据流离开Flink系统后进入到的位置，槽可以是数据库或到其他系统的连接器

Flink的流处理思想与Storm类似，以source接入数据，通过不同的operator进行transformation，最后输出到sink。

（3 ）、Flink的优势

与Spark相同，Flink也提供了较为完整的数据处理方式。除了上面介绍的流处理(DataStream API)和批处理(DataSet API)之外，Flink还提供了类SQL查询(Table API)、图计算(Gelly)和机器学习库(Flink ML)。而令人惊讶的是，在很多性能测试中，Flink甚至略优于Spark。

在目前的数据处理框架领域，Flink可谓独树一帜。虽然Spark同样也提供了批处理和流处理的能力，但Spark流处理的微批次架构使其响应时间略长。Flink流处理优先的方式实现了低延迟、高吞吐和真正逐条处理。

（4）、Flink局限性

同样，Flink也并不是完美的。Flink目前最大的缺点就是缺乏在大型公司实际生产项目中的成功应用案例。相对于Spark来讲，它还不够成熟，社区活跃度也没有Spark那么高。但假以时日，Flink必然会改变数据处理框架的格局。

（5）、Flink批处理模型

Flink的批处理模型在很大程度上仅仅是对流处理模型的扩展。此时模型不再从持续流中读取数据，而是从持久存储中以流的形式读取有边界的数据集。Flink会对这些处理模型使用完全相同的运行时。

Flink可以对批处理工作负载实现一定的优化。例如由于批处理操作可通过持久存储加以支持，Flink可以不对批处理工作负载创建快照。数据依然可以恢复，但常规处理操作可以执行得更快。

另一个优化是对批处理任务进行分解，这样即可在需要的时候调用不同阶段和组件。借此Flink可以与集群的其他用户更好地共存。对任务提前进行分析使得Flink可以查看需要执行的所有操作、数据集的大小，以及下游需要执行的操作步骤，借此实现进一步的优化。

（6 ）Flink批处理模型优势和局限

Flink目前是处理框架领域一个独特的技术。虽然Spark也可以执行批处理和流处理，但Spark的流处理采取的微批架构使其无法适用于很多用例。Flink流处理为先的方法可提供低延迟，高吞吐率，近乎逐项处理的能力。

Flink的很多组件是自行管理的。虽然这种做法较为罕见，但出于性能方面的原因，该技术可自行管理内存，无需依赖原生的Java垃圾回收机制。与Spark不同，待处理数据的特征发生变化后Flink无需手工优化和调整，并且该技术也可以自行处理数据分区和自动缓存等操作。

Flink会通过多种方式对工作进行分许进而优化任务。这种分析在部分程度上类似于SQL查询规划器对关系型数据库所做的优化，可针对特定任务确定最高效的实现方法。该技术还支持多阶段并行执行，同时可将受阻任务的数据集合在一起。对于叠代式任务，出于性能方面的考虑，Flink会尝试在存储数据的节点上执行相应的计算任务。此外还可进行「增量叠代」，或仅对数据中有改动的部分进行叠代。

在用户工具方面，Flink提供了基于Web的调度视图，借此可轻松管理任务并查看系统状态。用户也可以查看已提交任务的优化方案，借此了解任务最终是如何在集群中实现的。对于分析类任务，Flink提供了类似SQL的查询，图形化处理，以及机器学习库，此外还支持内存计算。

Flink能很好地与其他组件配合使用。如果配合Hadoop 堆栈使用，该技术可以很好地融入整个环境，在任何时候都只占用必要的资源。该技术可轻松地与YARN、HDFS和Kafka 集成。在兼容包的帮助下，Flink还可以运行为其他处理框架，例如Hadoop和Storm编写的任务。

目前Flink最大的局限之一在于这依然是一个非常「年幼」的项目。现实环境中该项目的大规模部署尚不如其他处理框架那么常见，对于Flink在缩放能力方面的局限目前也没有较为深入的研究。随着快速开发周期的推进和兼容包等功能的完善，当越来越多的组织开始尝试时，可能会出现越来越多的Flink部署。

总结

Flink提供了低延迟流处理，同时可支持传统的批处理任务。Flink也许最适合有极高流处理需求，并有少量批处理任务的组织。该技术可兼容原生Storm和Hadoop程序，可在YARN管理的集群上运行，因此可以很方便地进行评估。其快速开发的工作效率，引起人们的关注。

在大数据领域的广泛使用，因此仍推荐作为初学者学习数据处理框架的首选。虽然MapReduce因为性能原因以后的应用会越来越少，但是YARN和HDFS依然作为其他框架的基础组件被大量使用(比如HBase依赖于HDFS，YARN可以为Spark、Samza等框架提供资源管理)。学习Hadoop可以为以后的进阶打下基础。

在目前的企业应用中应该是当之无愧的王者。在批处理领域，虽然Spark与MapReduce的市场占有率不相上下，但Spark稳定上升，而MapReduce却稳定下降。而在流处理领域，Spark Streaming与另一大流处理系统Apache Storm共同占据了大部分市场(当然很多公司会使用内部研发的数据处理框架，但它们多数并不开源)。伯克利的正统出身、活跃的社区以及大量的商用案例都是Spark的优势。除了可用于批处理和流处理系统，Spark还支持交互式查询、图计算和机器学习。Spark在未来几年内仍然会是大数据处理的主流框架，推荐同学们认真学习。

另一个作为混合处理框架的Apache Flink则潜力无限，被称作「下一代数据处理框架」。虽然目前存在社区活跃度不够高、商用案例较少等情况，不过「是金子总会发光」，如果Flink能在商业应用上有突出表现，则可能挑战Spark的地位。

???

虽然Kafka被广泛应用于各种流处理系统做数据源，但Samza可以更好的发挥Kafka架构的优势。根据官网的解释，Samza由三个层次组成：

①.数据流层、②.执行层、③.处理层

性对应的支持三个层次的组件分别为：①.Kafka、②.YARN、③.Samza API

（2）、Samza优势和局限

也就是说，Samza使用Kafka提供了数据流，使用YARN进行资源管理，自身仅提供了操作数据流的API。Samza对Kafka和YARN的依赖在很多方面上与MapReduce对HDFS和YARN的依赖相似。

如果已经拥有Hadoop集群和Kafka集群环境，那么使用Samza作为流处理系统无疑是一个非常好的选择。由于可以很方便的将处理过的数据再次写入Kafka，Samza尤其适合不同团队之间合作开发，处理不同阶段的多个数据流。

乍看之下，Samza对Kafka类查询系统的依赖似乎是一种限制，然而这也可以为系统提供一些独特的保证和功能，这些内容也是其他流处理系统不具备的。

例如Kafka已经提供了可以通过低延迟方式访问的数据存储副本，此外还可以为每个数据分区提供非常易用且低成本的多订阅者模型。所有输出内容，包括中间态的结果都可写入到Kafka，并可被下游步骤独立使用。

这种对Kafka的紧密依赖在很多方面类似于MapReduce引擎对HDFS的依赖。虽然在批处理的每个计算之间对HDFS的依赖导致了一些严重的性能问题，但也避免了流处理遇到的很多其他问题。

Samza与Kafka之间紧密的关系使得处理步骤本身可以非常松散地耦合在一起。无需事先协调，即可在输出的任何步骤中增加任意数量的订阅者，对于有多个团队需要访问类似数据的组织，这一特性非常有用。多个团队可以全部订阅进入系统的数据话题，或任意订阅其他团队对数据进行过某些处理后创建的话题。这一切并不会对数据库等负载密集型基础架构造成额外的压力。

直接写入Kafka还可避免回压(Backpressure)问题。回压是指当负载峰值导致数据流入速度超过组件实时处理能力的情况，这种情况可能导致处理工作停顿并可能丢失数据。按照设计，Kafka可以将数据保存很长时间，这意味着组件可以在方便的时候继续进行处理，并可直接重启动而无需担心造成任何后果。

Samza可以使用以本地键值存储方式实现的容错检查点系统存储数据。这样Samza即可获得「至少一次」的交付保障，但面对由于数据可能多次交付造成的失败，该技术无法对汇总后状态(例如计数)提供精确恢复。

Samza提供的高级抽象使其在很多方面比Storm等系统提供的基元(Primitive)更易于配合使用。目前Samza只支持JVM语言，这意味着它在语言支持方面不如Storm灵活。

（3 ）、Samza总结

对于已经具备或易于实现Hadoop和Kafka的环境，Apache Samza是流处理工作负载一个很好的选择。Samza本身很适合有多个团队需要使用(但相互之间并不一定紧密协调)不同处理阶段的多个数据流的组织。Samza可大幅简化很多流处理工作，可实现低延迟的性能。如果部署需求与当前系统不兼容，也许并不适合使用，但如果需要极低延迟的处理，或对严格的一次处理语义有较高需求，此时依然适合考虑。
